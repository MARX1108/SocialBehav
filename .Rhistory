reg <- lm(df$aggressive_sumscore ~ ., data=ndf)
ndf <- df[fit$cluster==4, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==1, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==2, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==1, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==4, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==2, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
ndf <- df[fit$cluster==3, ]
reg <- lm(ndf$aggressive_sumscore ~ ., data=ndf)
summary(reg)
process(ndf, reg, upr)
0.41+0.72+0.33+0.53
1.99/4
0.412+0.5985
df <- subset(read.csv('cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
df <- subset(read.csv('cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
full <- lm(aggressive_sumscore ~ . + .^2, data=df)
summary(full)
process(df, reg, upr = -0.73254990)
process(df, full, upr = -0.73254990)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
print(cm$byclass)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- rep(TRUE, length(x))
#y[x < (qnt[1] - H)] <- FALSE
y[x > (qnt[2] + H)] <- FALSE
y
}
ls
df <- subset(read.csv('cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
#upr <- -0.3717866
df <- subset(read.csv('cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
full <- lm(aggressive_sumscore ~ ., data=df)
process(df, full, -0.73254990)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm$byclass)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- rep(TRUE, length(x))
#y[x < (qnt[1] - H)] <- FALSE
y[x > (qnt[2] + H)] <- FALSE
y
}
process(df, reg, upr = -0.73254990)
process(df, full, upr = -0.73254990)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
outliers <- function(x, na.rm = TRUE, ...) {
qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
H <- 1.5 * IQR(x, na.rm = na.rm)
y <- rep(TRUE, length(x))
#y[x < (qnt[1] - H)] <- FALSE
y[x > (qnt[2] + H)] <- FALSE
y
}
process(df, full, upr)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
newdf <- data.frame('y' = df$aggressive_sumscore)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
df <- subset(read.csv('cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
pwd
getwd
getwd()
df <- subset(read.csv('./cleandata.csv'), select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
odf <- read.csv('./cleandata.csv')
getwd()
setwd('./')
getwd()
setwd('./Desktop/andlab/code')
getwd()
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
}
setwd('./Desktop/andlab/code')
setwd('./Desktop/andlab/code')
setwd('~/Desktop/andlab/code')
odf <- read.csv('./cleandata.csv')
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
cm
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 0, ifelse(newdf$y>(upr),2,1))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 0, ifelse(newdf$fitted>(upr),2,1))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
cm <- process(df, reg, -0.73254990)
cm$byClass
cm$byClass['Precision']
View(cm)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
cm <- process(df, reg, -0.73254990)
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
print(cm$byClass)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
cm <- process(df, reg, -0.73254990)
odf <- read.csv('./cleandata.csv')
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
print(cm$byClass)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
knitr::opts_chunk$set(echo = TRUE)
odf <- read.csv('./cleandata.csv')
#setwd('~/Desktop/andlab/code')
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
print(cm)
print(cm$byClass)
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
odf <- read.csv('./cleandata.csv')
library('caret')
#setwd('~/Desktop/andlab/code')
df <- read.csv('cleandata.csv')
quantile(df$aggressive_sumscore, probs = c(0.75))
df[df$aggressive_sumscore  <= (-2.020650971) || df$aggressive_sumscore  >= (0.2168869)]
ndf<- df[df$aggressive_sumscore  <= (-2.020650971) || df$aggressive_sumscore  >= (0.2168869)]
ndf<- df[df$aggressive_sumscore  <= (-2.020650971) | df$aggressive_sumscore  >= (0.2168869)]
ndf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869))]
df$aggressive_sumscore  <= (-2.020650971)
ndf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
View(ndf)
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
## Analysis W/ Selected Data, All Attributes
```{r}
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
```
```
Attribute selection
```{r}
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
```
## Analysis W/ Selected Data, All Attributes
```{r}
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
```
```
Attribute selection
```{r}
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
```
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
## Analysis W/ Selected Data, All Attributes
```{r}
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
```
```
Attribute selection
```{r}
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
```
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
View(newdf)
confusionMatrix(table(newdf$class,newdf$pred_class))
confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
odf <- read.csv('./brain_cb')
odf <- read.csv('./brain_cb.csv')
odf <- read.csv('./brain_cb.csv')
odf <- read.csv('./brain_cb.csv')
setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
#setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
library('caret')
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, subjectkey))
df <- subset(odf, select=-c(prosocial_child, prosocial_parent, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
summary(reg)
cm <- process(df, reg, -0.73254990)
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
length(reg$fitted.values)
df <- subset(odf, select=-c(prosocial_child, prosocial_parent, subjectkey))
nrow(df)
reg <- lm(df$aggressive_sumscore ~ ., data=df)
length(reg$fitted.values)
#setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
na.omit(odf)
#setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
na.omit(odf)
nrow(odf)
#setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
odf <- odf[complete.cases(odf), ]
df <- subset(odf, select=-c(prosocial_child, prosocial_parent, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
summary(reg)
cm <- process(df, reg, -0.73254990)
df <- subset(odf, select=-c(prosocial_child, prosocial_parent, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.020650971), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.020650971), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
unique(newdf$class)
unique(newdf$pred_class)
df[df$aggressive_sumscore <= -2.020650971]
summary(df$aggressive_sumscore)
df[df$aggressive_sumscore <= -2.02065]
df[(df$aggressive_sumscore <= -2.02065)]
df[(df$aggressive_sumscore <= -2.02065),]
process <- function(df, reg, upr, plot=FALSE){
newdf <- data.frame('y' = df$aggressive_sumscore)
newdf$fitted <- reg$fitted.values
newdf$class <- ifelse(newdf$y <= (-2.02065), 'L', ifelse(newdf$y>(upr),'M','H'))
#change == -2.020650971 to change <= -2.020650971 to solve prediction for 0 is 0
newdf$pred_class <-ifelse(newdf$fitted <= (-2.02065), 'L', ifelse(newdf$fitted>(upr),'M','H'))
print(mean(newdf$pred_class == newdf$class))
#cm <- confusionMatrix(factor(newdf$pred_class, levels = 0:2), factor(newdf$class, levels = 0:2) )
cm <- confusionMatrix(table(newdf$class,newdf$pred_class))
if(plot)
{
par(mfrow = c(2, 2))
plot(reg)
}
return(cm=cm)
}
df <- subset(odf, select=-c(prosocial_child, prosocial_parent, subjectkey))
reg <- lm(df$aggressive_sumscore ~ ., data=df)
summary(reg)
cm <- process(df, reg, -0.73254990)
print(cm)
print(cm$byClass)
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf<- ifelse(odf$aggressive_sumscore <= (-2.020650971), 'L', 'H')
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf$y <- ifelse(odf$aggressive_sumscore <= (-2.020650971), 'L', 'H')
View(odf)
df <- subset(odf, select=-c(X,aggressive_sumscore , prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
glm.fit <- glm(y ~ ., data = df, family = binomial)
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf$y <- ifelse(odf$aggressive_sumscore <= (-2.020650971), 0, 1)
df <- subset(odf, select=-c(X,aggressive_sumscore , prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey))
glm.fit <- glm(y ~ ., data = df, family = binomial)
summary(glm.fit)
glm.fit$fitted.values
confusionMatrix(data = as.numeric(glm.fit$fitted.values>0.5), reference = df$y)
as.numeric(glm.fit$fitted.values>0.5)
df$y
confusionMatrix(as.numeric(glm.fit$fitted.values>0.5), reference = df$y)
confusionMatrix(table(as.numeric(glm.fit$fitted.values>0.5), f$y))
confusionMatrix(table(as.numeric(glm.fit$fitted.values>0.5), df$y))
cm <- confusionMatrix(table(as.numeric(glm.fit$fitted.values>0.5), df$y))
print(cm)
print(cm$byClass)
glm.fit <- glm(y ~ . + .^2, data = df, family = binomial)
library(MASS)
library(tidyverse)
glm.fit <- glm(y ~ ., data = df, family = binomial)
step.model <- glm.fit %>% stepAIC(trace = FALSE)
step.model
summary(step.model)
step.model$fitted.values
cm <- confusionMatrix(table(as.numeric(step.model$fitted.values>0.5), df$y))
print(cm)
print(cm$byClass)
df <- read.csv('cleandata.csv')
odf<- df[(df$aggressive_sumscore  <= (-2.020650971)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf$y <- ifelse(odf$aggressive_sumscore <= (-2.020650971), 0, 1)
df <- subset(odf, select=-c(X, prosocial_child, prosocial_parent, interview_date, interview_age, subjectkey, asr_scr_perstr_t, asr_scr_somaticpr_t, asr_scr_inattention_t,
crpbi_bothcare, kbi_p_c_best_friend, kbi_p_c_reg_friend_group, macv_p_ss_fs, macv_p_ss_fo, macv_p_ss_isr,macv_p_ss_fr, macv_p_ss_r, demo_prnt_age_v2, demo_prnt_marital_v2, demo_comb_income_v2, demo_yrs_1, demo_yrs_2, parent_rules_q1, parent_rules_q4, parent_rules_q7, su_risk_p_1, su_risk_p_2_3, su_risk_p_4_5, aggressive_sumscore))
glm.fit <- glm(y ~ ., data = df, family = binomial)
summary(glm.fit)
cm <- confusionMatrix(table(as.numeric(glm.fit$fitted.values>0.5), df$y))
print(cm)
print(cm$byClass)
glm.fit <- glm(y ~ . + .^2, data = df, family = binomial)
glm.fit <- glm(y ~ . + .^2, data = df, family = binomial)
step.model <- glm.fit %>% stepAIC(trace = FALSE)
#setwd('~/Desktop/andlab/code')
odf <- read.csv('./brain_cb.csv')
odf <- odf[complete.cases(odf), ]
odf <- read.csv('./brain_cb.csv')
odf <- odf[complete.cases(odf), ]
odf<- df[(df$aggressive_sumscore  <= (-2.02065)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf$y <- ifelse(odf$aggressive_sumscore <= (-2.02065), 0, 1)
library('caret')
odf <- read.csv('./brain_cb.csv')
odf <- odf[complete.cases(odf), ]
odf<- df[(df$aggressive_sumscore  <= (-2.02065)) | (df$aggressive_sumscore  >= (0.2168869)), ]
odf$y <- ifelse(odf$aggressive_sumscore <= (-2.02065), 0, 1)
library('caret')
